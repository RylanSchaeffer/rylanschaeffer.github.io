# Research

## Collaboration Requests

If you're interested in collaborating, email me at rylanschaeffer@gmail.com. I've posted
a (work-in-progress) [summary of my research approach](research/research_philosophy.md).

## Publications

### Under Review

- _Schaeffer_, et al. Testing Assumptions Underlying a Unified Theory for the Origin of Grid Cells.

- _Schaeffer_, et al. Beyond Expectations: Model-Driven Amplification of Dataset Biases in Data Feedback Loops.

- _Schaeffer_, et al. Divergence at the Interpolation Threshold: Identifying, Interpreting & Ablating the Sources of a Deep Learning Puzzle.

- _Schaeffer_, et al. An Information-Theoretic Understanding of Maximum Manifold Capacity Representations.

- _Schaeffer_, et al. Associative Memory Under the Probabilistic Lens: Improved Transformers & Dynamic Memory Creation.

### Accepted

- _Schaeffer_, Mirando, Koyejo. Are Emergent Abilities of Large Language Models a Mirage? __NeurIPS 2023 (Oral)__.

- _Schaeffer_, _Khona_, Ma, Eyzaguirre, Koyejo, Fiete. Self-Supervised Learning of Representations for Space Generates Multi-Modular Grid Cells. __NeurIPS 2023__. 
  
- Bricken, _Schaeffer_, Olshausen, Kreiman. Emergence of Sparse Representations from Noise. __ICML 2023__.

- _Schaeffer_, Khona, Fiete. No Free Lunch from Deep Learning in Neuroscience: A Case Study through Models
  of the Entorhinal-Hippocampal Circuit. __NeurIPS 2022__.

- _Schaeffer_, Liu, Du, Linderman, Fiete. Streaming Inference for Infinite Non-Stationary Clustering.
  __CoLLAs 2022__.

- _Schaeffer_, Du, Liu, Fiete. [Streaming Inference for Infinite Latent 
Feature Models.](research/2022_icml_streaming_ibp/main.html) __ICML 2022__.

- _Schaeffer_, Khona, Fiete. [No Free Lunch from Deep Learning in Neuroscience: 
A Case Study through Models of the Entorhinal-Hippocampal Circuit.](research/2022_icml_ai4science_no_free_lunch/main.html) __ICML 2022 Workshop: AI for Science__.

- _Schaeffer_, Liu, Du, Linderman, Fiete. [Streaming Inference for Infinite Non-Stationary Clustering.](research/2022_iclr_workshop_aloe/main.html)
  __ICLR 2022 Workshop: Agent Learning in Open Endedness__.

- _Schaeffer_. [An Algorithmic Theory of Metacognition in Minds and Machines.](research/2021_neurips_workshop_metacognition/main.html) 
  __NeurIPS 2021 Workshop: Metacognition in the Age of AI__.

- _Schaeffer_, et al. Fiete, IBL. [Neural population dynamics for hierarchical inference in mice performing 
the International Brain Lab task.](research/2021_sfn_ibl/main.html) __Society for Neuroscience 2021__.
  
- _Schaeffer_, Bordelon, Khona, Pan, Fiete. [Efficient Online Inference for Nonparametric Mixture Models.](research/2021_uai_streaming_crp/main.html) __UAI 2021__.

- _Schaeffer_, Shaham, Kreiman, Sompolinsky. [Neural network model of amygdalar memory engram formation 
  and function.](research/2021_cosyne_amygdalar_engram/main.html) __COSYNE 2021__.

- _Schaeffer_, Khona, Meshulam, IBL, Fiete. [Reverse-engineering recurrent neural network solutions to a hierarchical inference task for 
  mice.](research/2020_neurips_reverse_engineering/main.html) __NeurIPS 2020__.

### In Progress

- Liu, Schaeffer et al. Brain-wide population codes for hierarchical inference in mice. 2023.
  

## Rejected

- _Schaeffer_ et al. Double Descent Demystified: . __NeurIPS 2023__.

- _Schaeffer_ et al. Streaming Inference for Infinite Latent Feature Models. __AISTATS 2021__.

- _Schaeffer_ et al. Efficient Streaming Inference for Infinite Latent Feature Models. __ICML 2021 Workshop on Theory
  and Foundation of Continual Learning__.
  - [Paper](research/2021_icml_workshop_streaming_ibp/paper.pdf)

- _Schaeffer_ et al.
  Mechanistic neural circuit models of hierarchical inference. __COSYNE 2021__.
  - [2-Page Abstract](research/2021_cosyne_ibl_rnn/abstract.pdf) 

### One Day

- Schaeffer et al. Memory Engrams Perform Nonparametric Latent State Associative Learning. 2022.

- Schaeffer et al. Recovering low dimensional, interpretable mechanistic models
  via Representations and Dynamics Distillation. 2021.

### Abandoned

- Schaeffer et al. Towards Unifying Smooth 
  Neural Codes with Adversarially Robust Representations. 2019.
  - [Paper](research/2019_am226_smooth_neural_codes/paper.pdf)


## Explanations of Others' Research

- [Neural Turing Machines](research/neural_turing_machine/main.html)
- [One-shot Learning with Memory-Augmented Neural Networks](research/one_shot_learning_with_memory_augmented_nn/main.html)
- [Neural Episodic Control](research/neural_episodic_control/main.html)
- [Elastic Weight Consolidation](research/elastic_weight_consolidation/main.html)
- [Early Visual Concept Learning with Unsupervised Deep Learning](research/early_visual_concept_learning/main.html)
