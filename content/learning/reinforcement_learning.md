# Reinforcement Learning

## Introduction
- [Markov Process](stochastic_processes/markov_process.md)

## Value-Based RL
- [Rescorla-Wagner Learning Rule](reinforcement_learning/value_based/rescorla_wagner.md)
- Temporal Difference Learning
- Q-Learning  
- [Successor Representation](reinforcement_learning/successor_representation.md)

## Policy-Based RL
- [Policy Gradient Theorem](reinforcement_learning/policy_based/policy_gradient_theorem.md)
- [Improved Policy Gradient Estimators](reinforcement_learning/policy_based/improved_policy_gradient_estimators.md)

## Actor-Critic RL
- [Introduction](reinforcement_learning/actor_critic/introduction.md)

## Hierarchical RL (HRL)

### Options
- [Options (Sutton 1999)](reinforcement_learning/hierarchical_rl/options_sutton_1999.md)
- [Options Keyboard (Barreto 2019)](reinforcement_learning/hierarchical_rl/options_keyboard_barreto_2019.md)

### Feudal
- Feudal RL (Dayan 1992)
- Feudal Networks for HRL (Vezhnevets 2017)

### Bisimulation



## Distributional RL

- [Introduction](reinforcement_learning/distributional_rl/introduction.md)
- [Categorical (C51)](reinforcement_learning/distributional_rl/c51.md)
- Expectile Regression  
- [Quantile Regression](reinforcement_learning/distributional_rl/quantile_regression.md)

- Connection to Neuroscience: [Dabney et al. 2020](https://www.nature.com/articles/s41586-019-1924-6)

TODO
- https://proceedings.neurips.cc/paper/2020/file/9dd16e049becf4d5087c90a83fea403b-Paper.pdf


## Distributed RL

- [Ape-X](reinforcement_learning/distributed_rl/ape_x.md)
- [IMPALA](reinforcement_learning/distributed_rl/impala.md)
- [R2D2 (Kapturowski 2019)](reinforcement_learning/distributed_rl/r2d2.md)